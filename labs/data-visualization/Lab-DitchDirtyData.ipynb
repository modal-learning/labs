{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c72b24",
   "metadata": {},
   "source": [
    "# Ditch Dirty Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af36de3",
   "metadata": {},
   "source": [
    "Welcome to your SQL Data Cleaning lab! In this lab, we are going to work with a dirty dataset from Monster.com that lists job postings from February 2016 to January 2017. We need a clean dataset so that we can look at manager job trends across the USA for a data visualization project. \n",
    "\n",
    "For this lab, we’re just preparing the dataset and not making any visualizations, but it’s important to know why you’re cleaning and how you’ll use the data before you start cleaning up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514d5e1",
   "metadata": {},
   "source": [
    "## Welcome to SQL!\n",
    "\n",
    "SQL stands for Structured Query Language. It's a programming language that lets us store and retrieve important business data stored in _relational databases_. In the most basic terms, you can think of a relational database as a set of spreadsheets linked together. In SQL, we call these spreadsheets **tables**.\n",
    "\n",
    "### Table Structure\n",
    "\n",
    "If you've worked with spreadsheets before, SQL tables will look quite familiar. Tables are comprised rows and columns. Each row is called a **record**, and each column represents an **attribute** of that record.\n",
    "\n",
    "In our example dataset, each row represents a newly posted job listing on monster.com. The columns simply tell us more about that job by describing its attributes like `job_title`, `location`, or `salary`:\n",
    "\n",
    "**TODO: INSERT AN ILLUSTRATION**\n",
    "\n",
    "\n",
    "### Connecting to our Database\n",
    "\n",
    "The first step in working with SQL is connecting to our database. To get warmed up, try running the following command to create a new connection to our `jobs` database.\n",
    "\n",
    "_Note: You can use `SHIFT + RETURN` on any code block in this lab to run the code_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d210356",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load SQL\n",
    "%load_ext sql\n",
    "\n",
    "## Connect to our SQL database called \"jobs\"\n",
    "%sql sqlite:///jobs.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2987949",
   "metadata": {},
   "source": [
    "## Querying Our Database\n",
    "\n",
    "The first step in cleaning our dataset is being able to find the data we care about. SQL lets us write **queries** to do this.\n",
    "\n",
    "SQL queries generally start with a `SELECT` statement. `SELECT` helps us find the specific rows, or records, that match our query criteria.\n",
    "\n",
    "Let’s start with a simple query to get a taste of what our dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM jobs LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bdea21",
   "metadata": {},
   "source": [
    "So what's happening here? `SELECT` statements generally follow the format:\n",
    "\n",
    "```sql\n",
    "SELECT [columns] FROM [table_name] ... [QUERY FILTERS]\n",
    "```\n",
    "\n",
    "Here, we used the `*` operator as a shortcut for \"all columns\", and `LIMIT 2` as a query filter to only return the first 2 matching rows in our database.\n",
    "\n",
    "#### WHERE\n",
    "\n",
    "Instead of limiting ourselves to the first 2 results, let's see if there's other ways to filter the data. We can use the `WHERE` statement to help by giving our query specific criteria:\n",
    "\n",
    "A common pattern for filtering is:\n",
    "\n",
    "```sql\n",
    "WHERE [column_name] = [value]\n",
    "```\n",
    "\n",
    "Let's try it here by looking for the first 10 jobs that haven't expired:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93663890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM jobs WHERE has_expired = 'No' LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51efe8",
   "metadata": {},
   "source": [
    "We can use the `AND` operator to make more specific conditions for the `WHERE` statement.\n",
    "\n",
    "Let's update our query to look for active jobs in the U.S.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM jobs WHERE has_expired = 'No' AND country_code = 'US' LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7501a0f",
   "metadata": {},
   "source": [
    "Simple queries are ok on one line. But the bigger they get, it’s easier to space them out for readability. Let’s make this query a little easier to read by spacing it on multiple lines.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "\n",
    "SELECT * \n",
    "FROM jobs \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’;\n",
    "\n",
    "That query isn’t really filtering any better data. We have some columns like “country” and “has expired” that don’t add interesting information or distinctions in the data. Let’s clean it up and extract the data we care about to start to explore the trends. By adding only the columns we are interested in to the select clause, the query output becomes more useful. \n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’\n",
    "\n",
    "This is much easier to read, but there are still too many jobs to find meaningful trends. Let’s filter and try to classify the dataset and look at just the manager jobs in the dataset to see how manager jobs differ by state. By adding another AND clause we can search for job titles that are “Manager”.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs  \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’\n",
    "AND job_title = ‘Manager’;\n",
    "\n",
    "That was too restrictive of a search. Let’s use a wildcard to make sure we find all the instances. Wildcards are special characters that can stand in for unknown characters in a text value. For example our dataset may have included “product manager”. The wild card will make sure we don’t miss this entry. In SQL you use a % to enter a wildcard. \n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’\n",
    "AND job_title like ‘%Manager%’;\n",
    "\n",
    "Now we have all the manager jobs in the USA, but what about  “management” jobs? What if the dataset characterized manager roles with similar, but different terms? We won’t want to miss those in our analysis. You could try using different terms in your query to see the different results:\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’\n",
    "AND job_title like ‘%Manage%’;\n",
    "\n",
    "Or you could check for both by using an OR clause. Be sure to add parentheses around your OR clause to keep it a logical unit. Which version do you like better? The single view, or the combination? Which is easier to read?\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’\n",
    "AND (job_title like ‘%Manager%’ OR job_title like ‘%Management%’);\n",
    "\n",
    "What if you try a different capitalization of letters in your query? Does that change your results?\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’\n",
    "AND job_title like ‘%manage%’;\n",
    "\n",
    "Checking for all the capitalization combinations can be tedious. We can use the “upper” function to capitalize all often characters in a column for easy comparison.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’\n",
    "AND upper(job_title) like ‘%MANAG%’;\n",
    "\n",
    "I wonder if we’re missing anything else? To ensure we’re working with complete data, we need to know if we really have all the manager jobs. Let’s check the job description by using the same syntax that we used on the job title.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’\n",
    "AND upper(job_description) like ‘%MANAG%’;\n",
    "\n",
    "Looks like there are even more manager jobs! So now let’s try searching both columns in the same query.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’\n",
    "AND (upper(job_description) like ‘%MANAG%’\n",
    "OR upper(job_title) like ‘%MANAG%’);\n",
    "\n",
    "Are you starting to feel confident you found all your manager jobs? Great!\n",
    "\n",
    "Our data could still be cleaner! We can add a column called management which aggregates all of this management classification.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "ALTER TABLE  jobs ADD management text;\n",
    "\n",
    "Now you have one trustworthy management column for all the sources! Let’s add the data to it with an update statement.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "UPDATE TABLE  jobs SET management = ‘y’\n",
    "WHERE (upper(job_description) like ‘%MANAG%’\n",
    "OR upper(job_title) like ‘%MANAG%’);\n",
    "\n",
    "Now we have to classify the non-management jobs in your new column with the same update statement but reversing the logic with a NOT keyword.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "UPDATE TABLE  jobs SET management = ‘n’\n",
    "WHERE NOT (upper(job_description) like ‘%MANAG%’\n",
    "OR upper(job_title) like ‘%MANAG%’);\n",
    "\n",
    "Try out your new column in a query.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE has_expired = ‘n’ \n",
    "AND country_code = ‘US’\n",
    "AND management = ‘y’;\n",
    "Dig Deeper\n",
    "\n",
    "Let’s try these techniques again. Instead of focusing on manager as a classification, choose another job type - sales, engineering, etc.  Repeat the steps above and classify more data!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ditch Dirty Data: Consistent Data\n",
    "\n",
    "This is great, you have made your dataset cleaner and easier to use by classifying the job types! Let’s make it even easier to use by making our data more consistent. You are looking at trends for full time management roles in the USA. Let’s start by investigating the job type column.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE job_type = ‘Full Time’;\n",
    "\n",
    "The query returns lots of jobs, but are we sure we have all the full time jobs? Let’s widen the search again and consider other values. Let’s include a wild card again to make sure we don’t miss any entries.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE job_type like ‘Full Time%’;\n",
    "\n",
    "Capitalizations can be a challenge as well. We can add the function upper before the column name to capitalize all the entries. This will ensure we don’t miss any because of different capitalizations. \n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_type, job_title, location\n",
    "FROM jobs \n",
    "WHERE upper(job_type) = ‘%FULL TIME%’;\n",
    "\n",
    "How many versions of full time can you find? Let’s create a summary by making a count and grouping by the job type. Adding the function count(*) will count the entries, and adding GROUP BY will group the count by job type. \n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*), job_type\n",
    "FROM jobs \n",
    "GROUP BY job_type;\n",
    "\n",
    "That’s a lot of data. Let’s sort it by adding an ORDER BY COUNT that will sort the job types by the number of occurrences.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*), job_type\n",
    "FROM jobs \n",
    "GROUP BY job_type\n",
    "ORDER BY COUNT(*);\n",
    "\n",
    "Alternatively, you can reverse the sort by adding a desc for descending.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*), job_type\n",
    "FROM jobs \n",
    "GROUP BY job_type\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "There are a lot of variants of full time employees, let’s standardize them by modifying the values in the table.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "UPDATE TABLE  jobs SET job_type = ‘Full Time’\n",
    "WHERE job_type = ‘Full Time Employee’;\n",
    "\n",
    "Good start, but did you get them all? Check the count query again.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*), job_type\n",
    "FROM jobs \n",
    "GROUP BY job_type\n",
    "ORDER BY COUNT(*);\n",
    "\n",
    "You can add wildcards in the middle of a search too to find even more relevant entries.\n",
    "\n",
    "In the notebook, type:\n",
    "UPDATE TABLE  jobs SET job_type = ‘Full Time’\n",
    "WHERE job_type = ‘Full Time%Employee’;\n",
    "\n",
    "How many did you get now? See if there are any other entries that you want to clean up. \n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*), job_type\n",
    "FROM jobs \n",
    "GROUP BY job_type\n",
    "ORDER BY COUNT(*);\n",
    "\n",
    "You know what is annoying in data? No data. How many of those job titles are blank? By using the “is null” syntax in your query you can find the entries that are empty. \n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT job_title, job_description\n",
    "FROM jobs \n",
    "WHERE job_type is null;\n",
    "\n",
    "After scanning those jobs, let’s assume they are full time.  Update them in the table to full time.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "UPDATE TABLE  jobs SET job_type = ‘Full Time’\n",
    "WHERE job_type is null;\n",
    "Dig Deeper\n",
    "\n",
    "How consistent does this data seem now? Do you trust the job types enough? Do some more clean up if you think you can find more issues! Look for entries that seem completely wrong and repeat the steps above to improve your dataset.\n",
    "\n",
    "\n",
    "Ditch Dirty Data: Splitting Data\n",
    "\n",
    "Next, let’s investigate the location of these jobs by counting the different locations in the dataset. There’s just one column to describe the location, start by counting up the unique entries.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*), location\n",
    "FROM jobs \n",
    "GROUP BY location\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "Wow, lots of issues here! The city, state and zipcode are all combined in one field. Let’s get started by adding some new columns.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "ALTER TABLE  jobs ADD city text;\n",
    "\n",
    "\n",
    "ALTER TABLE  jobs ADD state text;\n",
    "\n",
    "\n",
    "ALTER TABLE  jobs ADD zip text;\n",
    "\n",
    "We need to start by finding some zip codes. To start with, use the “right” function to get the rightmost five characters from the location. Let’s assume the last 5 characters are always the zip code.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*),  right(location, 5)\n",
    "FROM jobs \n",
    "GROUP BY right(location, 5)\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "Well that has too much noise, not all fields have zip codes and not all fields even look like valid locations. Let’s use a new zip codes reference table to check if our last 5 characters are actually a valid zip code. We do this with the IN clause and embedding a new select statement.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*),  right(location, 5)\n",
    "FROM jobs \n",
    "WHERE right(location, 5) IN (SELECT zip from zipcodes)\n",
    "GROUP BY right(location, 5)\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "Now that we have validated the data in the zipcodes table we can use the IN clause in an UPDATE statement to update our new zip code column.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "UPDATE jobs SET zip = right(location,5)\n",
    "WHERE right(location, 5) IN (SELECT zip from zipcodes)\n",
    "GROUP BY right(location, 5)\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "How about the States next? Scan the data for patterns.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*), location\n",
    "FROM jobs \n",
    "GROUP BY location\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "Let’s check out the data for state and no zip codes (for example “Dallas, TX”).\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*),  right(location, 2)\n",
    "FROM jobs \n",
    "WHERE right(location, 2) IN (SELECT zip from zipcodes)\n",
    "GROUP BY right(location, 2)\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "Do you trust that data? How about when you check for 3 characters, you’d expect that extra character to be a space first before the State ID and how adding an “upper” would have been an issue?\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*),  right(location, 3)\n",
    "FROM jobs \n",
    "GROUP BY right(location, 3)\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "Hint: check out: \n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*),  right(location, 3), upper(right(location,2))\n",
    "FROM jobs \n",
    "WHERE location = ‘Big Data Architect’;\n",
    "\n",
    "Can we try another way to get the state? Is it better to assume it is the 2 characters after a comma? For example: Orlando, FL 32816. Since city names are variable length we can retrieve the first 3 characters after a comma. Use the “instr” function to find the position of the comma and the substring to get the next 3 characters.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*),  substring(location, instr(location, ‘,’),3)\n",
    "FROM jobs \n",
    "GROUP BY substring(location, instr(location, ‘,’),3)\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "Adding the validation check back into the query for the state and using the “right” function to get just the two characters.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*),  right(substring(location, instr(location, ‘,’),3),2)\n",
    "FROM jobs \n",
    "WHERE right(substring(location, instr(location, ‘,’),3), 2) \n",
    "IN (SELECT state_id from zipcodes)\n",
    "GROUP BY right(substring(location, instr(location, ‘,’),3),2)\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "Now you have a consistent way to get a valid state, you can update the your new state field.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "UPDATE jobs SET state =  right(substring(location, instr(location, ‘,’),3),2)\n",
    "WHERE right(substring(location, instr(location, ‘,’),3), 2) \n",
    "IN (SELECT state_id from zipcodes);\n",
    "\n",
    "By modifying the use of instr and substring, we can use similar logic to retrieve the city. But now we assume the city is everything from the first character to the comma. To exclude the comma we want the character position one less than its location.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*),  substring(location, 1,instr(location, ‘,’)-1)\n",
    "FROM jobs \n",
    "WHERE substring(location, 1, instr(location, ‘,’)-1)\n",
    "IN (SELECT state_id from zipcodes)\n",
    "GROUP BY substring(location, 1, instr(location, ‘,’)-1)\n",
    "ORDER BY COUNT(*) desc;\n",
    "\n",
    "By modifying the use of instr and substring, we can use similar logic to retrieve the city.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "UPDATE jobs set city = substring(location, 1,instr(location, ‘,’)-1)\n",
    "WHERE substring(location, 1, instr(location, ‘,’)-1)\n",
    "IN (SELECT city from zipcodes);\n",
    "Dig Deeper\n",
    "\n",
    "Our solution to parsing out cities and states made assumptions around the format of the location data. Write a query to review how the new city and state data was populated and correct any major issues with an update statement that targets just one row at a time. \n",
    "\n",
    "Ditch Dirty Data: Complete Your Analysis\n",
    "\n",
    "We now have a clean dataset that has reliable data for full time managers by state. Let’s see if there is a trend of job postings.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*), date_added, state\n",
    "FROM jobs \n",
    "WHERE job_type = ‘Full Time’\n",
    "AND manager = ‘y’\n",
    "GROUP BY state, date_added\n",
    "ORDER BY state, date_added\n",
    "\n",
    "It will be challenging to find a clear pattern by day, let’s group by month. Use the TRUNC function to set each date to the first of the month.\n",
    "\n",
    "In the notebook, type:\n",
    "\n",
    "SELECT count(*), trunc(date_added, ‘MM’), state\n",
    "FROM jobs \n",
    "WHERE job_type = ‘Full Time’\n",
    "AND manager = ‘y’\n",
    "GROUP BY trunc(date_added, ‘MM’), state\n",
    "ORDER BY state, trunc(date_added, ‘MM’)\n",
    "\n",
    "Congratulations! You’ve cleaned up a super messy dataset and focused the data on answering a specific question. You’ve learned all sorts of queries and functions that you can use on any dataset.\n",
    "Dig Deeper\n",
    "\n",
    "Want to reference back to these queries and functions? Here’s a cheat sheet with all the queries. Happy cleaning!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Appendix: Tables\n",
    "\n",
    "Jobs: https://www.kaggle.com/PromptCloudHQ/us-jobs-on-monstercom\n",
    "country\n",
    "country_code\n",
    "Date_added\n",
    "has_expired\n",
    "job_board\n",
    "job_description\n",
    "job_title\n",
    "job_type\n",
    "location\n",
    "Organization\n",
    "\n",
    "Zipcodes: https://simplemaps.com/data/us-zips\n",
    "zip\n",
    "city\n",
    "State_id\n",
    "Appendix: Cheat Sheet\n",
    "\n",
    "TBD after finalize the lesson. Will have all queries and functions written out as a cheat code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069fbac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
